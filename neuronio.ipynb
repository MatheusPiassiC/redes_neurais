{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMM55+n0XlGcB4eP+1R08ut",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatheusPiassiC/redes_neurais/blob/main/neuronio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Estudo de implementação de neurônio simples para uma rede neural\n",
        "Baseado no notebook do professor Denilson Alves Pereira, junto de seus conteúdos gravados."
      ],
      "metadata": {
        "id": "McxuKM6aWTVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "lvqGHq7kW11n"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Enunciado\n",
        "O problema consiste em classificar um conjunto de dados hipotéticos. Cada instância é composta por 4 atributos (0 ou 1), sendo que a saída deve ser um 0 ou 1 (classificaçãso binária), e é determinada pelo valor do primeiro atributo da instância.\n",
        "\n",
        "Ou seja, se a instância for [1,0,0,1], a saída será 1\n",
        "\n",
        "Vale lembrar que neste código, as instâncias são representadas pelas colunas, e os atributos pelas linhas, como mostrado no trecho de código abaixo."
      ],
      "metadata": {
        "id": "duRqKNRBXFnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array([[0, 1, 0, 1, 1, 0],   #como dito anteriormente, são 6 instâncias de 4 atributos.\n",
        "                    [0, 1, 1, 0, 0, 1],\n",
        "                    [0, 0, 0, 1, 0, 1],\n",
        "                    [1, 0, 0, 0, 1, 1]])\n",
        "\n",
        "y_train = np.array([0, 1, 0, 1, 1, 0])    #saída esperada do conjunto de treino\n",
        "\n"
      ],
      "metadata": {
        "id": "uhCJa9LqXwxw"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array([[1, 0, 1], #conjunto de teste\n",
        "                   [1, 1, 1],\n",
        "                   [0, 1, 1],\n",
        "                   [1, 0, 1]])\n",
        "\n",
        "y_test = np.array([[1, 0, 1]]) #saidas esperadas do conjunto de teste"
      ],
      "metadata": {
        "id": "EKv3YSWfbsKs"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = X_train.shape[0] #numero de atributos (shape retorna um array com o numero de linhas e colunas)\n",
        "m = X_train.shape[1] #numero de exemplos de treino\n",
        "\n",
        "print(\"número de atributos: n=\" + str(n))\n",
        "print(\"número de exemplos de treino: m=\" + str(m))\n",
        "print(\"forma de X_train: \"+ str(X_train.shape))\n",
        "print(\"forma de y_train: \"+ str(y_train.shape))\n",
        "print(\"forma de X_test: \"+ str(X_test.shape))\n",
        "print(\"forma de y_test: \"+ str(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbh-_OA3btdA",
        "outputId": "1a8defa6-44d2-4cf4-eb17-36d6e2a1befd"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "número de atributos: n=4\n",
            "número de exemplos de treino: m=6\n",
            "forma de X_train: (4, 6)\n",
            "forma de y_train: (6,)\n",
            "forma de X_test: (4, 3)\n",
            "forma de y_test: (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Arquitetura\n",
        "A partir daqui, será implementado um classificador binário usando regressão logistica para resolver o problema.\n",
        "\n",
        "Calculo de z de uma instância x:\n",
        "\n",
        "$$z^{(i)} = w^T x^{(i)} + b$$\n",
        "\n",
        "Saída do neurônio usando função de ativação sigmoide:\n",
        "\n",
        "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})$$\n",
        "\n",
        "Função de perda da regressão logistica:\n",
        "\n",
        "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})$$\n",
        "\n",
        "OBS: A função de custo consiste no somatório das funções de perda."
      ],
      "metadata": {
        "id": "30UGw6undkUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Inicialização dos parâmetros\n",
        "Seguindo o exemplo utilizado, o próximo passo é iniciar os parametros *b* (bias, viés) e *w* (pesos para cada atributo). O tamanho do vetor *w* é igual ao número de atributos de uma entrada (neste caso, 4), pois precisamos de atribuir um peso para cada atributo, enquanto *b* é um escalar."
      ],
      "metadata": {
        "id": "eYoDR0uF0doy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iLYPBoRgdclS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initializeParameters(dim): #recebe o dim para saber o tamanho do vetor w\n",
        "  w = np.zeros((dim,1)) #4 LINHAS e 1 coluna, para seguir o padrâo do código\n",
        "  b = 0.0 #inicializa o bias\n",
        "  return w, b"
      ],
      "metadata": {
        "id": "xGixZzgM1fqP"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim = n\n",
        "w,b = initializeParameters(dim)\n",
        "print(\"w = \"+ str(w))\n",
        "print(\"b = \"+ str(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpdgiNap268G",
        "outputId": "dc24866c-09b0-486d-d479-257d607cafff"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w = [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "b = 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Função sigmóide\n",
        "Este trecho computa a função sigóide a partir de um *z*:\n",
        "\n",
        "$sigmoid(z) = \\frac{1}{1 + e^{-(z)}}$"
      ],
      "metadata": {
        "id": "fHs8hd1T3YOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  s = 1/(1 + np.exp(-z))\n",
        "  return s"
      ],
      "metadata": {
        "id": "n1OszDjx4D86"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"sigmoid([0, 1, 2, 8]) = \" + str(sigmoid(np.array([0,1,2,8]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_EYzT_V4bNm",
        "outputId": "a7671699-60d1-41f6-b60f-4529513b667d"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigmoid([0, 1, 2, 8]) = [0.5        0.73105858 0.88079708 0.99966465]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Propagação para frente (feed foward)\n",
        "Executa a propagaçãom para frente através do calculo da função sigmoide para um determinado *z* ( considere que $z = w^T X + b$ ).\n",
        "Através no *numpy*, este cálculo pode ser feito de forma paralelizada para vários valores, por isso, usaremos um vetor X e calcularemos a sigmoide para cada *x* (lembrando que x é uma instância) em *X* (que é uma matriz)\n",
        "\n",
        "Deste modo, o calculo de $z$ seria algo como:\n",
        "\n",
        "$z = x^{(1)}w^{(1)} + x^{(2)}w^{(2)} + ... + b$\n",
        "\n",
        "Sendo X = [[0, 1, 0, 1, 1, 0],  \n",
        "          [0, 1, 1, 0, 0, 1],\n",
        "          [0, 0, 0, 1, 0, 1],\n",
        "          [1, 0, 0, 0, 1, 1]]\n",
        "\n",
        "E sendo W = [[1],\n",
        "            [2],\n",
        "            [3],\n",
        "            [4]]\n",
        "\n",
        "Nós queremos múltiplicar cada linha de uma coluna de X (que corresponde a uma instância/entrada) por cada linha de W. Para mantermos a propriedade que permite a multiplicação de matrizes (o número de colunas da primeira matriz deve ser igual ao número de linhas da segunda matriz), precisamos de transpor W. Segue um exemplo para a primeira entrada (ou seja, primeira coluna) de X.\n",
        "\n",
        "Daí, teriamos algo parecido como:\n",
        "\n",
        "$z = (0*1) + (0*2) + (0*3) + (1*4) + b$\n",
        "\n",
        "Essa fórmula para o cálculo de $z$ é usada como parêmtro para a sigmoide, que retorna uma lista de resoltados para cada coluna de X.\n",
        "\n",
        " $A = \\sigma(w^T X + b) = (a^{(1)}, a^{(2)}, ..., a^{(m-1)}, a^{(m)})$"
      ],
      "metadata": {
        "id": "agJPre8o4gS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feed_forward(w,b,X):\n",
        "  A = sigmoid(np.dot(w.T, X)+b) #np.dot realiza multiplicações de vetores e matrizes\n",
        "  return A"
      ],
      "metadata": {
        "id": "MkYMp2uPAUfJ"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#teste 1\n",
        "w, b, X = np.array([[0.5],[2.]]), 2., np.array([[1.,-2.,1.],[4.,3.,-2.3]])\n",
        "A = feed_forward(w, b, X)\n",
        "print(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPmKHRgQBB9B",
        "outputId": "3ac398b2-97f0-4b3d-8948-d994307709fa"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.99997246 0.99908895 0.10909682]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#teste 2\n",
        "w, b = initializeParameters(dim)\n",
        "A = feed_forward(w, b, X_train)\n",
        "print(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY_40fFjBRt_",
        "outputId": "4c805a4e-7c74-4645-b28e-4af82749c0a3"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5 0.5 0.5 0.5 0.5 0.5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Propagação para trás (backpropagation)\n",
        "Computa a função de custo, ou seja, o a média das funções de perda para cada entrada. Também calcula as derivadas parciais de $w$ e $b$."
      ],
      "metadata": {
        "id": "IphiVKGgBaYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagation(A,X,Y): #\"A\" é o conjunto de saidas da sigmoide\n",
        "  m = X.shape[1] #número de colunas de X, ou seja, o número de exemplos\n",
        "  cost = -(np.sum(Y*np.log(A)+(1-Y)*np.log(1-A)))/m #média dos somatório das funções de perda, ou seja, a função de custo\n",
        "  dw = (np.dot(X,(A-Y).T))/m #calcula dw\n",
        "  db = (np.sum(A-Y))/m       #calcula db\n",
        "  cost = np.squeeze(cost) #remove eixos desmecessários\n",
        "  grads = {\"dw\": dw,\n",
        "           \"db\": db}\n",
        "  return grads, cost"
      ],
      "metadata": {
        "id": "gRGzRINYMVq3"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w, b, X, Y = np.array([[0.5],[2.]]), 2., np.array([[1.,-2.,1.],[4.,3.,-2.3]]), np.array([[1,0,1]])\n",
        "A = feed_forward(w, b, X)\n",
        "grads, cost = backpropagation(A, X, Y)\n",
        "print (\"dw = \" + str(grads[\"dw\"]))\n",
        "print (\"db = \" + str(grads[\"db\"]))\n",
        "print (\"cost = \" + str(cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtQZZUswOFaY",
        "outputId": "486789ca-e88a-41de-a919-421dea7da7c2"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dw = [[-0.9630362]\n",
            " [ 1.682078 ]]\n",
            "db = 0.03605274477003254\n",
            "cost = 3.072152841901268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelo de treino\n",
        "Este trecho executa o algoritmo de descida de gradiente para otimizar os valores dos parâmetros $w$ e $b$. O objetivo é aprender os melhores valores para as variáveis $w$ e $b$ de modo a minimizar a função de custo.\n",
        "\n",
        "Para um parâmetro $\\theta$, a regra de atualização é $\\theta = \\theta - \\alpha \\text{ } d\\theta$, onde $\\alpha$ é a taxa de aprendizagem."
      ],
      "metadata": {
        "id": "2_-Uqp2dOf-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X, Y, epochs = 1000, alpha = 0.005, print_cost = False):\n",
        "  costs = []\n",
        "  n = X.shape[0] #número de atributos de cada instância\n",
        "  w,b = initializeParameters(n) #inicializa w e b\n",
        "\n",
        "  for i in range(epochs):\n",
        "    A = feed_forward(w,b,X) #calcula as saidas com base na função sigmoide\n",
        "    grads, cost = backpropagation(A,X,Y) #faz o backpropagation\n",
        "    dw = grads[\"dw\"]  #guarda dw\n",
        "    db = grads[\"db\"]  #guarda db\n",
        "    w = w - alpha * dw #atualiza os pesos w com base em dw e na taxa de aprendizado alpha\n",
        "    b = b - alpha * db #atualiza o bias com base em db e na taxa de aprendizado\n",
        "    if i % 100 == 0:\n",
        "      costs.append(cost)\n",
        "    if print_cost and i % 100 == 0:\n",
        "      print (\"Custo na iteração %i: %f\" %(i, cost))\n",
        "  params = {\"w\": w,\n",
        "            \"b\": b}\n",
        "  return params, costs\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BlRCOnBSPMQA"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testando\n",
        "X, Y = np.array([[1.,-2.,1.],[4.,3.,-2.3]]), np.array([[1,0,1]])\n",
        "\n",
        "params, costs = train(X, Y, epochs = 100, alpha = 0.009, print_cost = False)\n",
        "\n",
        "print (\"w = \" + str(params[\"w\"]))\n",
        "print (\"b = \" + str(params[\"b\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SBaQj4jRBgD",
        "outputId": "306382c6-f5a9-45ae-eab9-225b28b9bc31"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w = [[ 0.47673328]\n",
            " [-0.05236593]]\n",
            "b = 0.14693555740530975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predição de novos valores\n",
        "Agora que já treinamos o nosso neurônio, podemos usar os pesos e o bias obtido para tentar prever novos valores.\n",
        "\n",
        "Basicamente, executamos o feed forward e em seguida convertemos os valores para o padrão de saída:\n",
        "\n",
        "  Se a saida for <= 0.5:  0\n",
        "  \n",
        "  Se a saída for > 0.5: 1"
      ],
      "metadata": {
        "id": "OmpMPsJmRqRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(w, b, X): #prediz um conjunto de saídas para um determinado X, com base nos pesos e no bias\n",
        "  m = X.shape[1] #número de colunas de X, ou seja, número de instâncias\n",
        "  Y_pred = np.zeros((1,m))\n",
        "  w = w.reshape(X.shape[0], 1) #transforma w em um vetor coluna\n",
        "  A = feed_forward(w, b, X) #faz o fedd forward\n",
        "  for i in range(A.shape[1]):\n",
        "    Y_pred[0,i] = 1 if A[0,i] > 0.5 else 0 #transforma as saídas em 0 ou 1\n",
        "  return Y_pred\n"
      ],
      "metadata": {
        "id": "DEc06mYbSsVb"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = np.array([[1.24076588],[0.75978603]])\n",
        "b = -0.18\n",
        "X = np.array([[0,0,0],[0,1,1]])\n",
        "print (\"predictions = \" + str(predict(w, b, X)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSpFK48pTida",
        "outputId": "d009e31d-7c21-4ea0-a392-e75a0351ec39"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions = [[0. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Avaliação do modelo\n",
        "A avaliação proposta é feita da seguinte forma:\n",
        "1. Usa os dados de treinamento para gerar o *modelo de aprendizagem*, para aprender $w$ e $b$.\n",
        "2. Calcula a acurácia obtida pelo modelo de treino.\n",
        "3. Obtém a predição a partir dos dados de teste, com os parâmetros aprendidos.\n",
        "4. Calcula a acurácia obtida nos dados de teste.\n",
        "\n",
        "O esperado é que o custo diminua com o passar das iterações durante o aprendizado. Como o modelo é bastante simples, com apenas uma *epoch* já é possível obter acurácia de 100%."
      ],
      "metadata": {
        "id": "knzErxAGTsvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"treinando...\")\n",
        "params, costs = train(X_train, y_train, epochs = 1000, alpha = 0.005, print_cost = True)\n",
        "print(\"treinado!\")\n",
        "w = params[\"w\"]\n",
        "b = params[\"b\"]\n",
        "\n",
        "\n",
        "print(\"Acurácia do treino: \")\n",
        "y_pred = predict(w, b, X_train)\n",
        "print(100 - np.mean(np.abs(y_pred - y_train)) * 100)\n",
        "\n",
        "print(\"testando...\")\n",
        "y_pred = predict(w, b, X_test)\n",
        "print(100 - np.mean(np.abs(y_pred - y_test)) * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9giZied4UlTq",
        "outputId": "d52f3eef-019a-4918-b821-d2baab2e94ae"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "treinando...\n",
            "Custo na iteração 0: 0.693147\n",
            "Custo na iteração 100: 0.656550\n",
            "Custo na iteração 200: 0.622944\n",
            "Custo na iteração 300: 0.592033\n",
            "Custo na iteração 400: 0.563555\n",
            "Custo na iteração 500: 0.537278\n",
            "Custo na iteração 600: 0.512996\n",
            "Custo na iteração 700: 0.490522\n",
            "Custo na iteração 800: 0.469690\n",
            "Custo na iteração 900: 0.450349\n",
            "treinado!\n",
            "Acurácia do treino: \n",
            "100.0\n",
            "testando...\n",
            "100.0\n"
          ]
        }
      ]
    }
  ]
}